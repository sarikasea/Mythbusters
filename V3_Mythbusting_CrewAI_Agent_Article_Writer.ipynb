{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkP9BMzHBcAqUGRjROyKwT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3858b13ede3e44d580857951cd757463": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_5878c7bcd8d842c19aec0c079c621f4d",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[1;36mğŸš€ Crew: \u001b[0m\u001b[1;36mcrew\u001b[0m\nâ””â”€â”€ \u001b[1;33mğŸ“‹ Task: 16bae635-daa7-4479-ba1b-055d7cc36759\u001b[0m\n    \u001b[37mStatus: \u001b[0m\u001b[2;33mExecuting Task...\u001b[0m\n    â””â”€â”€ \u001b[1;31mâŒ LLM Failed\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ğŸš€ Crew: crew</span>\nâ””â”€â”€ <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ğŸ“‹ Task: 16bae635-daa7-4479-ba1b-055d7cc36759</span>\n    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Status: </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">Executing Task...</span>\n    â””â”€â”€ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">âŒ LLM Failed</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "5878c7bcd8d842c19aec0c079c621f4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarikasea/Mythbusters/blob/main/V3_Mythbusting_CrewAI_Agent_Article_Writer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(np.__version__+' is numpy version')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bevmh67UYtAc",
        "outputId": "fb9c9347-4171-4195-f9db-049d70e2f796"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.26.4 is numpy version\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q crewai crewai_tools langchain_community langchain_google_genai google-serp-api python-dotenv\n",
        "print('done - crew ai & langchain installed')"
      ],
      "metadata": {
        "id": "wCjNuyLp0M-k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a51d3e60-4e31-4461-bc12-2df27e6ed03b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done - crew ai & langchain installed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import warnings\n",
        "from crewai import Agent, Task, Crew\n",
        "from crewai_tools import SerperDevTool\n",
        "from langchain.tools import Tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "from IPython.display import display, Markdown\n",
        "from google.colab import userdata\n",
        "\n",
        "# Ignore unnecessary warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BvG3gY0bIfn",
        "outputId": "c6151a88-976c-4ccf-c28e-fcafa5bad532"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pydantic/fields.py:1093: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'required'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from crewai_tools import SerperDevTool\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"SERPER_API_KEY\"] =  userdata.get('SERPER_API_KEY')\n",
        "search_tool = SerperDevTool()"
      ],
      "metadata": {
        "id": "wQZxo_R-bc_t"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, let's use the search_tool to perform a search\n",
        "try:\n",
        "    # Pass the search term as a keyword argument 'query'\n",
        "    results = search_tool.run(query=\"latest news on veganism\")\n",
        "\n",
        "    # The 'results' variable is already a formatted string from the tool.\n",
        "    # We can just print it directly.\n",
        "    print(results)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaCs4iyJb648",
        "outputId": "e3adac4b-dbb1-4761-c679-3ced28aef991"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Tool: Search the internet with Serper\n",
            "{'searchParameters': {'q': 'latest news on veganism', 'type': 'search', 'num': 10, 'engine': 'google'}, 'organic': [{'title': \"Today's Top Vegan News Stories - VegNews.com\", 'link': 'https://vegnews.com/news', 'snippet': \"Food News of the Week: Vegan Octopus Returns, Beyond's Whole-Cut Steak, Â· Chrissy Teigen's Reflux Struggles Are So Relatable, and Why We Love the Gut-Friendly.\", 'position': 1}, {'title': 'Plant Based News: Home', 'link': 'https://plantbasednews.org/', 'snippet': \"James Cromwell Says He Went Vegan On Day Two Of Filming 'Babe'. After nearly 20 years of vegetarianism, James Cromwell went vegan on the second day of ...\", 'position': 2, 'sitelinks': [{'title': 'All News', 'link': 'https://plantbasednews.org/all/'}, {'title': 'About Us', 'link': 'https://plantbasednews.org/about-us/'}, {'title': 'Other News', 'link': 'https://plantbasednews.org/category/news/'}, {'title': 'Opinion', 'link': 'https://plantbasednews.org/category/opinion/'}]}, {'title': 'Veganism - The New York Times', 'link': 'https://www.nytimes.com/topic/subject/veganism', 'snippet': 'For Health, More Nuts, Beans and Whole Grains. Plant-based foods are linked to a lower risk of heart disease and diabetes, a new study shows.', 'position': 3}, {'title': 'Latest News - vegconomist - the vegan business magazine', 'link': 'https://vegconomist.com/', 'snippet': 'Latest news and current trends from the vegan business world. Discover the growing market for plant-based products and stay up to date on cellular ...', 'position': 4}, {'title': 'The Latest Vegan News', 'link': 'https://www.veganfoodandliving.com/news/', 'snippet': 'Dale Vince-backed vegan petition reaches major milestone, sparking hope for a Greener Britain. A petition for plant-based food promotion has hit 10,000 ...', 'position': 5}, {'title': 'Veganism | The Guardian', 'link': 'https://www.theguardian.com/lifeandstyle/veganism', 'snippet': 'London becomes first vegan restaurant in UK to win a Michelin star. Feb 11 2025 13.39 EST Dog treat made from lab-grown meat on sale in UK as retailer claims a ...', 'position': 6}, {'title': 'Latest Research News - The Vegan Society |', 'link': 'https://www.vegansociety.com/get-involved/research/research-news', 'snippet': 'Researcher Network member, Tani Khara, discusses the key insights from her recent research into the dog and cat meat.', 'position': 7}, {'title': 'VegNews: Plant-Based Food + Lifestyle', 'link': 'https://vegnews.com/', 'snippet': 'VegNews is an award-winning vegan magazine and website packed with recipes, travel, news, food, reviews, and so much more.', 'position': 8, 'sitelinks': [{'title': 'News', 'link': 'https://vegnews.com/news'}, {'title': 'Recipes', 'link': 'https://vegnews.com/recipes'}, {'title': 'Customer Service', 'link': 'https://vegnews.com/customercare'}, {'title': 'Contact Us', 'link': 'https://vegnews.com/contact'}]}, {'title': '/r/Vegan - the largest vegan community online! - Reddit', 'link': 'https://www.reddit.com/r/vegan/', 'snippet': 'BREAKING: Big Ag and their allies in Congress want to fast-track a new Farm Bill that would roll back critical animal protections and strip states of the power ...', 'position': 9}], 'relatedSearches': [{'query': 'Latest news on veganism today'}, {'query': 'Vegan News'}, {'query': 'Plant-based News'}, {'query': 'Vegan News 2024'}, {'query': 'Vegan magazine subscription'}, {'query': 'Vegan Food and Living'}, {'query': 'Best vegan magazine'}, {'query': 'plant-based news - youtube'}], 'credits': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import userdata\n",
        "\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# --- Set the Environment Variable Here ---\n",
        "# Paste your key from the working cell in your screenshot\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "# Now, the rest of your code will work because the environment variable is set\n",
        "model_name = os.getenv(\"GOOGLE_MODEL\", \"gemini-1.5-pro-latest\")\n",
        "\n",
        "print(f\"Successfully loaded Google LLM: {model_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yf6VyN6yZZmk",
        "outputId": "561d23df-eacb-405f-c157-d8f9122713e3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded Google LLM: gemini-1.5-pro-latest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# This is the most reliable way to configure the Gemini LLM for CrewAI.\n",
        "# It ensures the model name is sent correctly to Google's API.\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-pro-latest\",\n",
        "    # The API key is automatically read from your environment variables,\n",
        "    # so you don't need to pass it here.\n",
        "    temperature=0.7,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# This test call will now work correctly\n",
        "try:\n",
        "    response = llm.invoke(\"Explain how AI works in a few words\")\n",
        "    print(response.content)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8BSbDlKplqb",
        "outputId": "994fabfc-d50d-4dc5-f6ec-b71534103807"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI mimics human intelligence using algorithms and data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#AGENTS"
      ],
      "metadata": {
        "id": "MB2ZqP6Qf0xx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ResearchAgent = Agent(\n",
        "    name=\"HistoricalFactFinder\",\n",
        "    role=(\n",
        "        \"You are a specialized historical researcher. Your task is to gather detailed, \"\n",
        "        \"fact-checked information on a given historical figure ({topic}). You must find \"\n",
        "        \"information to cover the following specific sections: \"\n",
        "        \"1. Era/Country, 2. Love Life, 3. Scientific/Political Contribution, \"\n",
        "        \"4. Misunderstanding/Scandal, 5. End of Life/Legacy, \"\n",
        "        \"6. Recommended books about them, 7. Notable Quotes from them, \"\n",
        "        \"8. Songs/Movies about them.\"\n",
        "    ),\n",
        "    goal=(\n",
        "        \"Compile a comprehensive report on {topic} with detailed notes and verifiable \"\n",
        "        \"sources for each of the eight required sections. This report will be used to \"\n",
        "        \"write a structured, myth-busting article.\"\n",
        "    ),\n",
        "    backstory=(\n",
        "        \"You are a meticulous historian with a passion for primary sources and \"\n",
        "        \"academic databases. You excel at separating fact from fiction and providing \"\n",
        "        \"the raw material for compelling historical narratives.\"\n",
        "    ),\n",
        "    tools=[search_tool], # Add other tools like web_search_tool as needed\n",
        "    llm=llm,\n",
        "    memory=True,\n",
        "    allow_delegation=False,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# Writer agent: Now tasked with writing an article with the specified structure.\n",
        "WriterAgent = Agent(\n",
        "    name=\"NarrativeWeaver\",\n",
        "    role=(\n",
        "        \"You are an expert writer specializing in historical biographies. Your task is to \"\n",
        "        \"transform research notes about {topic} into an engaging myth-busting article.\"\n",
        "    ),\n",
        "    goal=(\n",
        "        \"Write a captivating article about {topic} that is clearly structured into the \"\n",
        "        \"following eight sections: 1. Historical Context (Era/Country), \"\n",
        "        \"2. Personal Life & Relationships, 3. Major Contributions & Achievements, \"\n",
        "        \"4. Scandals & Misconceptions, 5. Final Years & Lasting Legacy, \"\n",
        "        \"6. Further Reading (Recommended Books), 7. Memorable Quotes, \"\n",
        "        \"8. Pop Culture Portrayals (Songs/Movies). The article must be engaging, \"\n",
        "        \"educational, and based strictly on the provided research.\"\n",
        "    ),\n",
        "    backstory=(\n",
        "        \"As a journalist and cultural analyst for a popular history blog, you know how to \"\n",
        "        \"make history come alive. You craft narratives that are not only informative but \"\n",
        "        \"also challenge common misinformation, especially concerning women in history.\"\n",
        "    ),\n",
        "    llm=llm,\n",
        "    memory=True,\n",
        "    allow_delegation=False,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# Editor agent: Now responsible for checking for the presence and quality of the 8 sections.\n",
        "EditorAgent = Agent(\n",
        "    name=\"ContentChief\",\n",
        "    role=(\n",
        "        \"You are a meticulous editor with expertise in feminist history and public education.\"\n",
        "        \"You will review a draft article for clarity, factual accuracy, and tone.\"\n",
        "    ),\n",
        "    goal=(\n",
        "        \"Polish the myth-busting article about {topic}, ensuring it aligns with the goal \"\n",
        "        \"of accessible public education. You must verify that: \"\n",
        "        \"1. All facts are clearly explained and well-cited. \"\n",
        "        \"2. The tone is professional yet accessible. \"\n",
        "        \"3. All eight required sections (Era, Love Life, Contributions, Scandal, Legacy, \"\n",
        "        \"Books, Quotes, Media) are present, well-developed, and seamlessly integrated.\"\n",
        "    ),\n",
        "    backstory=(\n",
        "        \"With years of experience editing for historical journals and online magazines, \"\n",
        "        \"you have a sharp eye for detail and a deep understanding of how to present \"\n",
        "        \"complex historical truths to a broad audience. Your standard is excellence.\"\n",
        "    ),\n",
        "    llm=llm,\n",
        "    memory=True,\n",
        "    allow_delegation=False,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "3w9jN_HRcjtG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_myth_busting_workflow(topic):\n",
        "    research_task = Task(\n",
        "        agent=ResearchAgent,\n",
        "        description=f\"Research common myths about {topic} and gather accurate historical information to refute them.\",\n",
        "        expected_output=\"Bullet points with sources about myths and true facts\"\n",
        "    )"
      ],
      "metadata": {
        "id": "q-Yev9USlS-r"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TASKS\n"
      ],
      "metadata": {
        "id": "Z3L8PkUVfx8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew\n",
        "\n",
        "# (You would have the Agent definitions and the 'article_sections' dictionary from the previous step here)\n",
        "# ...\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. DEFINE THE TASKS THAT ALIGN WITH THE AGENT GOALS\n",
        "# ==============================================================================\n",
        "\n",
        "# Note: The `description` for each task is now precisely aligned with the agent's role\n",
        "# and our shared `article_sections` structure.\n",
        "\n",
        "research_task = Task(\n",
        "    agent=ResearchAgent,\n",
        "    description=(\n",
        "        \"Find detailed, fact-checked information on the historical figure: {topic}. \"\n",
        "        \"Your research must provide material for all eight of the required sections. \"\n",
        "        \"Focus on uncovering details that can bust common myths or add surprising depth.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A comprehensive report as a single text document. The report must be clearly \"\n",
        "        \"structured with headings for each of the 8 required sections, containing detailed \"\n",
        "        \"notes and verifiable sources for each section.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "writing_task = Task(\n",
        "    agent=WriterAgent,\n",
        "    description=(\n",
        "        \"Using the provided research report on {topic}, write a captivating, myth-busting \"\n",
        "        \"article of approximately 1200 words. The article's structure must strictly \"\n",
        "        \"follow the 8 required sections. Weave the research into a compelling narrative \"\n",
        "        \"that is both educational and engaging.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A complete, well-written article draft, formatted with clear headings for each of the \"\n",
        "        \"8 sections. The tone should be engaging and accessible to a general audience.\"\n",
        "    ),\n",
        "    context=[research_task] # This task depends on the output of the research_task\n",
        ")\n",
        "\n",
        "editing_task = Task(\n",
        "    agent=EditorAgent,\n",
        "    description=(\n",
        "        \"Review the provided article draft about {topic}. Your review must focus on several key areas: \"\n",
        "        \"1. Verify that all 8 required sections are present, well-developed, and logically structured. \"\n",
        "        \"2. Check all facts against the source material for accuracy. \"\n",
        "        \"3. Polish the writing for clarity, engagement, and consistent tone. \"\n",
        "        \"4. Ensure the article successfully fulfills its 'myth-busting' goal.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"The final, publishable version of the article on {topic}. It should be free of errors, \"\n",
        "        \"factually pristine, and ready for an audience.\"\n",
        "    ),\n",
        "    context=[writing_task] # This task depends on the output of the writing_task\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "MOwKUg74dYU-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the list of topics you want to process\n",
        "topics_to_process = [\"Cleopatra\", \"Marie Curie\"]\n",
        "\n",
        "# Loop through each topic and run the full workflow for each one\n",
        "for topic in topics_to_process:\n",
        "    print(f\"\\n\\n=============================================\")\n",
        "    print(f\"ğŸš€ Starting New Workflow for Topic: {topic}\")\n",
        "    print(f\"=============================================\")\n",
        "\n",
        "    # Create the Crew for the current topic\n",
        "    crew = Crew(\n",
        "        agents=[ResearchAgent, WriterAgent, EditorAgent],\n",
        "        tasks=[research_task, writing_task, editing_task],\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    # Kick off the workflow with the current topic\n",
        "    result = crew.kickoff(inputs={\"topic\": topic})\n",
        "\n",
        "    # Print the final result for the current topic\n",
        "    print(f\"\\n\\nâœ… Final Result for {topic}:\")\n",
        "    display(Markdown(result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3858b13ede3e44d580857951cd757463",
            "5878c7bcd8d842c19aec0c079c621f4d"
          ]
        },
        "id": "6bQBWpmMmoFW",
        "outputId": "bb4a4a45-2cd8-403d-8e73-f0576058ae84"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "=============================================\n",
            "ğŸš€ Starting New Workflow for Topic: Cleopatra\n",
            "=============================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[36mâ•­â”€\u001b[0m\u001b[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[36m Crew Execution Started \u001b[0m\u001b[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[36mâ”€â•®\u001b[0m\n",
              "\u001b[36mâ”‚\u001b[0m                                                                                                                 \u001b[36mâ”‚\u001b[0m\n",
              "\u001b[36mâ”‚\u001b[0m  \u001b[1;36mCrew Execution Started\u001b[0m                                                                                         \u001b[36mâ”‚\u001b[0m\n",
              "\u001b[36mâ”‚\u001b[0m  \u001b[37mName: \u001b[0m\u001b[36mcrew\u001b[0m                                                                                                     \u001b[36mâ”‚\u001b[0m\n",
              "\u001b[36mâ”‚\u001b[0m  \u001b[37mID: \u001b[0m\u001b[36mf01565be-95d1-4020-a230-4b7f288ae3b4\u001b[0m                                                                       \u001b[36mâ”‚\u001b[0m\n",
              "\u001b[36mâ”‚\u001b[0m  \u001b[37mTool Args: \u001b[0m                                                                                                    \u001b[36mâ”‚\u001b[0m\n",
              "\u001b[36mâ”‚\u001b[0m                                                                                                                 \u001b[36mâ”‚\u001b[0m\n",
              "\u001b[36mâ”‚\u001b[0m                                                                                                                 \u001b[36mâ”‚\u001b[0m\n",
              "\u001b[36mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Crew Execution Started â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Crew Execution Started</span>                                                                                         <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #008080; text-decoration-color: #008080\">crew</span>                                                                                                     <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">ID: </span><span style=\"color: #008080; text-decoration-color: #008080\">f01565be-95d1-4020-a230-4b7f288ae3b4</span>                                                                       <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Tool Args: </span>                                                                                                    <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[35mâ•­â”€\u001b[0m\u001b[35mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[35m ğŸ¤– Agent Started \u001b[0m\u001b[35mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[35mâ”€â•®\u001b[0m\n",
              "\u001b[35mâ”‚\u001b[0m                                                                                                                 \u001b[35mâ”‚\u001b[0m\n",
              "\u001b[35mâ”‚\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mYou are a specialized historical researcher. Your task is to gather detailed, fact-checked information\u001b[0m  \u001b[35mâ”‚\u001b[0m\n",
              "\u001b[35mâ”‚\u001b[0m  \u001b[1;92mon a given historical figure (Cleopatra). You must find information to cover the following specific sections:\u001b[0m  \u001b[35mâ”‚\u001b[0m\n",
              "\u001b[35mâ”‚\u001b[0m  \u001b[1;92m1. Era/Country, 2. Love Life, 3. Scientific/Political Contribution, 4. Misunderstanding/Scandal, 5. End of \u001b[0m    \u001b[35mâ”‚\u001b[0m\n",
              "\u001b[35mâ”‚\u001b[0m  \u001b[1;92mLife/Legacy, 6. Recommended books about them, 7. Notable Quotes from them, 8. Songs/Movies about them.\u001b[0m         \u001b[35mâ”‚\u001b[0m\n",
              "\u001b[35mâ”‚\u001b[0m                                                                                                                 \u001b[35mâ”‚\u001b[0m\n",
              "\u001b[35mâ”‚\u001b[0m  \u001b[37mTask: \u001b[0m\u001b[92mFind detailed, fact-checked information on the historical figure: Cleopatra. Your research must provide\u001b[0m  \u001b[35mâ”‚\u001b[0m\n",
              "\u001b[35mâ”‚\u001b[0m  \u001b[92mmaterial for all eight of the required sections. Focus on uncovering details that can bust common myths or \u001b[0m    \u001b[35mâ”‚\u001b[0m\n",
              "\u001b[35mâ”‚\u001b[0m  \u001b[92madd surprising depth.\u001b[0m                                                                                          \u001b[35mâ”‚\u001b[0m\n",
              "\u001b[35mâ”‚\u001b[0m                                                                                                                 \u001b[35mâ”‚\u001b[0m\n",
              "\u001b[35mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ¤– Agent Started â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">You are a specialized historical researcher. Your task is to gather detailed, fact-checked information</span>  <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">on a given historical figure (Cleopatra). You must find information to cover the following specific sections:</span>  <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">1. Era/Country, 2. Love Life, 3. Scientific/Political Contribution, 4. Misunderstanding/Scandal, 5. End of </span>    <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Life/Legacy, 6. Recommended books about them, 7. Notable Quotes from them, 8. Songs/Movies about them.</span>         <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Task: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">Find detailed, fact-checked information on the historical figure: Cleopatra. Your research must provide</span>  <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">material for all eight of the required sections. Focus on uncovering details that can bust common myths or </span>    <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">add surprising depth.</span>                                                                                          <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">â”‚</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3858b13ede3e44d580857951cd757463"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31mâ•­â”€\u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31m LLM Error \u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31mâ”€â•®\u001b[0m\n",
              "\u001b[31mâ”‚\u001b[0m                                                                                                                 \u001b[31mâ”‚\u001b[0m\n",
              "\u001b[31mâ”‚\u001b[0m  \u001b[1;31mâŒ LLM Call Failed\u001b[0m                                                                                             \u001b[31mâ”‚\u001b[0m\n",
              "\u001b[31mâ”‚\u001b[0m  \u001b[37mError: \u001b[0m\u001b[31mlitellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. \u001b[0m   \u001b[31mâ”‚\u001b[0m\n",
              "\u001b[31mâ”‚\u001b[0m  \u001b[31mYou passed model=models/gemini-1.5-pro-latest\u001b[0m                                                                  \u001b[31mâ”‚\u001b[0m\n",
              "\u001b[31mâ”‚\u001b[0m  \u001b[31m Pass model as E.g. For 'Huggingface' inference endpoints pass in \u001b[0m                                             \u001b[31mâ”‚\u001b[0m\n",
              "\u001b[31mâ”‚\u001b[0m  \u001b[31m`completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\u001b[0m              \u001b[31mâ”‚\u001b[0m\n",
              "\u001b[31mâ”‚\u001b[0m                                                                                                                 \u001b[31mâ”‚\u001b[0m\n",
              "\u001b[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ LLM Error â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">âŒ LLM Call Failed</span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Error: </span><span style=\"color: #800000; text-decoration-color: #800000\">litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. </span>   <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000\">You passed model=models/gemini-1.5-pro-latest</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000\"> Pass model as E.g. For 'Huggingface' inference endpoints pass in </span>                                             <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000\">`completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers</span>              <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31mâ•­â”€\u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31m Task Failure \u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31mâ”€â•®\u001b[0m\n",
              "\u001b[31mâ”‚\u001b[0m                                                                                                                 \u001b[31mâ”‚\u001b[0m\n",
              "\u001b[31mâ”‚\u001b[0m  \u001b[1;31mTask Failed\u001b[0m                                                                                                    \u001b[31mâ”‚\u001b[0m\n",
              "\u001b[31mâ”‚\u001b[0m  \u001b[37mName: \u001b[0m\u001b[31m16bae635-daa7-4479-ba1b-055d7cc36759\u001b[0m                                                                     \u001b[31mâ”‚\u001b[0m\n",
              "\u001b[31mâ”‚\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[31mYou are a specialized historical researcher. Your task is to gather detailed, fact-checked information\u001b[0m  \u001b[31mâ”‚\u001b[0m\n",
              "\u001b[31mâ”‚\u001b[0m  \u001b[31mon a given historical figure (Cleopatra). You must find information to cover the following specific sections:\u001b[0m  \u001b[31mâ”‚\u001b[0m\n",
              "\u001b[31mâ”‚\u001b[0m  \u001b[31m1. Era/Country, 2. Love Life, 3. Scientific/Political Contribution, 4. Misunderstanding/Scandal, 5. End of \u001b[0m    \u001b[31mâ”‚\u001b[0m\n",
              "\u001b[31mâ”‚\u001b[0m  \u001b[31mLife/Legacy, 6. Recommended books about them, 7. Notable Quotes from them, 8. Songs/Movies about them.\u001b[0m         \u001b[31mâ”‚\u001b[0m\n",
              "\u001b[31mâ”‚\u001b[0m  \u001b[37mTool Args: \u001b[0m                                                                                                    \u001b[31mâ”‚\u001b[0m\n",
              "\u001b[31mâ”‚\u001b[0m                                                                                                                 \u001b[31mâ”‚\u001b[0m\n",
              "\u001b[31mâ”‚\u001b[0m                                                                                                                 \u001b[31mâ”‚\u001b[0m\n",
              "\u001b[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Task Failure â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Task Failed</span>                                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #800000; text-decoration-color: #800000\">16bae635-daa7-4479-ba1b-055d7cc36759</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #800000; text-decoration-color: #800000\">You are a specialized historical researcher. Your task is to gather detailed, fact-checked information</span>  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000\">on a given historical figure (Cleopatra). You must find information to cover the following specific sections:</span>  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000\">1. Era/Country, 2. Love Life, 3. Scientific/Political Contribution, 4. Misunderstanding/Scandal, 5. End of </span>    <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000\">Life/Legacy, 6. Recommended books about them, 7. Notable Quotes from them, 8. Songs/Movies about them.</span>         <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Tool Args: </span>                                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31mâ•­â”€\u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31m Crew Failure \u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31mâ”€â•®\u001b[0m\n",
              "\u001b[31mâ”‚\u001b[0m                                                                                                                 \u001b[31mâ”‚\u001b[0m\n",
              "\u001b[31mâ”‚\u001b[0m  \u001b[1;31mCrew Execution Failed\u001b[0m                                                                                          \u001b[31mâ”‚\u001b[0m\n",
              "\u001b[31mâ”‚\u001b[0m  \u001b[37mName: \u001b[0m\u001b[31mcrew\u001b[0m                                                                                                     \u001b[31mâ”‚\u001b[0m\n",
              "\u001b[31mâ”‚\u001b[0m  \u001b[37mID: \u001b[0m\u001b[31mf01565be-95d1-4020-a230-4b7f288ae3b4\u001b[0m                                                                       \u001b[31mâ”‚\u001b[0m\n",
              "\u001b[31mâ”‚\u001b[0m  \u001b[37mTool Args: \u001b[0m                                                                                                    \u001b[31mâ”‚\u001b[0m\n",
              "\u001b[31mâ”‚\u001b[0m  \u001b[37mFinal Output: \u001b[0m                                                                                                 \u001b[31mâ”‚\u001b[0m\n",
              "\u001b[31mâ”‚\u001b[0m                                                                                                                 \u001b[31mâ”‚\u001b[0m\n",
              "\u001b[31mâ”‚\u001b[0m                                                                                                                 \u001b[31mâ”‚\u001b[0m\n",
              "\u001b[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Crew Failure â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Crew Execution Failed</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #800000; text-decoration-color: #800000\">crew</span>                                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">ID: </span><span style=\"color: #800000; text-decoration-color: #800000\">f01565be-95d1-4020-a230-4b7f288ae3b4</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Tool Args: </span>                                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Final Output: </span>                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "BadRequestError",
          "evalue": "litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=models/gemini-1.5-pro-latest\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-22-1707504620.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Kick off the workflow with the current topic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkickoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"topic\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtopic\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Print the final result for the current topic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/crew.py\u001b[0m in \u001b[0;36mkickoff\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sequential_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhierarchical\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_hierarchical_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/crew.py\u001b[0m in \u001b[0;36m_run_sequential_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_sequential_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCrewOutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0;34m\"\"\"Executes tasks sequentially and returns the final output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_tasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_hierarchical_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCrewOutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/crew.py\u001b[0m in \u001b[0;36m_execute_tasks\u001b[0;34m(self, tasks, start_index, was_replayed)\u001b[0m\n\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m                 \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m                 task_output = task.execute_sync(\n\u001b[0m\u001b[1;32m    884\u001b[0m                     \u001b[0magent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magent_to_use\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m                     \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/task.py\u001b[0m in \u001b[0;36mexecute_sync\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    354\u001b[0m     ) -> TaskOutput:\n\u001b[1;32m    355\u001b[0m         \u001b[0;34m\"\"\"Execute the task synchronously.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/task.py\u001b[0m in \u001b[0;36m_execute_core\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mcrewai_event_bus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTaskFailedEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m  \u001b[0;31m# Re-raise the exception after emitting the event\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_process_guardrail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_output\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTaskOutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mGuardrailResult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/task.py\u001b[0m in \u001b[0;36m_execute_core\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_by_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mcrewai_event_bus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTaskStartedEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             result = agent.execute_task(\n\u001b[0m\u001b[1;32m    421\u001b[0m                 \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agent.py\u001b[0m in \u001b[0;36mexecute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    460\u001b[0m                     ),\n\u001b[1;32m    461\u001b[0m                 )\n\u001b[0;32m--> 462\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_times_executed\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_times_executed\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retry_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agent.py\u001b[0m in \u001b[0;36mexecute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    436\u001b[0m                 )\n\u001b[1;32m    437\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_without_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agent.py\u001b[0m in \u001b[0;36m_execute_without_timeout\u001b[0;34m(self, task_prompt, task)\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0moutput\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \"\"\"\n\u001b[0;32m--> 534\u001b[0;31m         return self.agent_executor.invoke(\n\u001b[0m\u001b[1;32m    535\u001b[0m             {\n\u001b[1;32m    536\u001b[0m                 \u001b[0;34m\"input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtask_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mformatted_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             self._printer.print(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36m_invoke_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"litellm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                     \u001b[0;31m# Do not retry on litellm errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_context_length_exceeded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     handle_context_length(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/crew_agent_executor.py\u001b[0m in \u001b[0;36m_invoke_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0menforce_rpm_limit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_within_rpm_limit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 answer = get_llm_response(\n\u001b[0m\u001b[1;32m    155\u001b[0m                     \u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                     \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/utilities/agent_utils.py\u001b[0m in \u001b[0;36mget_llm_response\u001b[0;34m(llm, messages, callbacks, printer, from_task, from_agent)\u001b[0m\n\u001b[1;32m    158\u001b[0m         )\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         printer.print(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/utilities/agent_utils.py\u001b[0m in \u001b[0;36mget_llm_response\u001b[0;34m(llm, messages, callbacks, printer, from_task, from_agent)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;34m\"\"\"Call the LLM and return the response, handling any invalid responses.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         answer = llm.call(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/llm.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, messages, tools, callbacks, available_functions, from_task, from_agent)\u001b[0m\n\u001b[1;32m    969\u001b[0m                     )\n\u001b[1;32m    970\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m                     return self._handle_non_streaming_response(\n\u001b[0m\u001b[1;32m    972\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavailable_functions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_task\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/llm.py\u001b[0m in \u001b[0;36m_handle_non_streaming_response\u001b[0;34m(self, params, callbacks, available_functions, from_task, from_agent)\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# across the codebase. This allows CrewAgentExecutor to handle context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0;31m# length issues appropriately.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlitellm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mContextWindowExceededError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0;31m# Convert litellm's context window error to our own exception type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1304\u001b[0m                     \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback_exception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m                 )  # DO NOT MAKE THREADED - router retry fallback relies on this!\n\u001b[0;32m-> 1306\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1179\u001b[0m                     \u001b[0mprint_verbose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error while checking max token limit: {str(e)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;31m# MODEL CALL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m             \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m             if _is_streaming_request(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/main.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[0m\n\u001b[1;32m   3428\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3429\u001b[0m         \u001b[0;31m## Map to OpenAI Exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3430\u001b[0;31m         raise exception_type(\n\u001b[0m\u001b[1;32m   3431\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3432\u001b[0m             \u001b[0mcustom_llm_provider\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_llm_provider\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/main.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeployment_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m             \u001b[0mcustom_llm_provider\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"azure\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m         model, custom_llm_provider, dynamic_api_key, api_base = get_llm_provider(\n\u001b[0m\u001b[1;32m   1101\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0mcustom_llm_provider\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_llm_provider\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/get_llm_provider_logic.py\u001b[0m in \u001b[0;36mget_llm_provider\u001b[0;34m(model, custom_llm_provider, api_base, api_key, litellm_params)\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlitellm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBadRequestError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             error_str = (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/get_llm_provider_logic.py\u001b[0m in \u001b[0;36mget_llm_provider\u001b[0;34m(model, custom_llm_provider, api_base, api_key, litellm_params)\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0merror_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model={model}\\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;31m# maps to openai.NotFoundError, this is raised when openai does not recognize the llm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m             raise litellm.exceptions.BadRequestError(  # type: ignore\n\u001b[0m\u001b[1;32m    357\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadRequestError\u001b[0m: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=models/gemini-1.5-pro-latest\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rbY7Ak4cmoSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OvTYrHvimobK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ESiHIbtmogD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zXQoSHPXmojD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4546f35a"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}